# AI Coding Assistant â€” Implementation Plan

## 1. AI Layer
- **Define interfaces**:
  ```go
  type LLM interface {
      Chat(messages []Message) (Response, error)
  }
  ```
- **Implementations**:
  - `ClaudeClient` (Anthropic API)
  - `OpenAIClient` (GPT-4/Code API)
- **Config**:
  - API keys, model selection, rate limits, retry policies.

---

## 2. Instruction Layer
- Define structured formats:
  - **Patch format** (Go package implementation).
  - **Tool calls** (JSON or typed structs).
  ```go
  type ToolCall struct {
      Name string
      Args map[string]string
  }
  ```
- Validation + parser for LLM output.
- Reprompt on invalid output.

---

## 3. Speech Layer
- **STT (Speech-to-Text)**: Whisper API/local.
- **TTS (Text-to-Speech)**: OpenAI TTS, Coqui, or Azure.
- Pipeline: user speaks â†’ STT â†’ orchestrator â†’ LLM â†’ orchestrator â†’ TTS reply.

---

## 4. Orchestrator
- Main control loop:
  1. Accepts user input (speech/text).
  2. Sends to AI Layer with current context.
  3. Parses response â†’ `Patch` or `ToolCall`.
  4. Executes via Tool Dispatcher (filesystem ops, run tests, search, etc.).
  5. Feeds results back to AI.
- **Modes**:
  - Confirm operations (default).
  - `--allow-all-operations` (no confirmations).
- After success â†’ trigger **auto-commit**.

---

## 5. Context Manager
- Maintains:
  - Open files.
  - Recent patches (summarized).
  - Operation history.
- Implements context trimming:
  - Retrieval of relevant snippets.
  - Summarization of older edits.
- Storage:
  - In-memory + persisted (SQLite, Redis, or local JSON).

---

## 6. Safety Layer
- **Docker sandbox**:
  - For compiling/running code.
  - For running tests.
- Enforce resource limits:
  - `--cpus=1`
  - `--memory=512m`
  - Execution timeouts.
- Collect stdout/stderr/exit code.
- Return structured results to AI Layer.

---

## 7. Version Control Integration
- After every successful operation:
  ```bash
  git add .
  git commit -m "Applied patch: fixed FooBar undefined error in main.go"
  ```
- Commit message generated by AI (based on last operation).

---

## ðŸš€ Execution Flow
1. **User speaks request**.
2. **Speech Layer â†’ Orchestrator**.
3. **Orchestrator â†’ AI Layer â†’ Instruction Layer**.
4. LLM responds with patch/tool call.
5. **Tool Dispatcher executes** (sandboxed if needed).
6. **Context Manager updated**.
7. **Auto-commit changes**.
8. **Speech Layer responds** (TTS).
