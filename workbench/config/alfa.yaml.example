# Alfa Configuration
# This file is automatically created and updated by alfa
# CLI arguments always take priority over these settings

# Workbench configuration
workbench:
  path: workbench                  # Workbench directory path
  project: ""                      # Default project name (empty = use context or prompt)

# AI provider configuration
ai:
  provider: anthropic              # Default provider: "anthropic" or "openai"
  selected_model: claude-sonnet-4-5-20250929  # Default model to use
  config_file: ""                  # Path to ai-config.json (empty = workbench/config/ai-config.json)
  providers:
    anthropic:
      default_model: claude-sonnet-4-5-20250929
      models:
        # Claude 4.x series (2025) - Latest models
        claude-sonnet-4-5-20250929:
          description: "Claude Sonnet 4.5: Most intelligent model, best for coding and complex agents"
          max_tokens: 64000
          temperature: 1.0
          timeout: 3m0s
          retry_count: 3
          retry_delay: 1s
        claude-opus-4-1-20250805:
          description: "Claude Opus 4.1: Latest Opus upgrade, powerful reasoning"
          max_tokens: 32000
          temperature: 1.0
          timeout: 3m0s
          retry_count: 3
          retry_delay: 1s
        claude-sonnet-4-20250514:
          description: "Claude Sonnet 4: Hybrid model with instant and extended thinking"
          max_tokens: 64000
          temperature: 1.0
          timeout: 3m0s
          retry_count: 3
          retry_delay: 1s
        # Claude 3.5 series (2024)
        claude-3-5-haiku-20241022:
          description: "Claude Haiku 3.5: Fast and cost-effective"
          max_tokens: 8192
          temperature: 1.0
          timeout: 1m0s
          retry_count: 3
          retry_delay: 1s
        claude-3-5-sonnet-20241022:
          description: "Claude Sonnet 3.5: Legacy model"
          max_tokens: 8192
          temperature: 1.0
          timeout: 1m0s
          retry_count: 3
          retry_delay: 1s
    openai:
      default_model: gpt-5
      models:
        gpt-5:
          description: "GPT-5: Unified system with smart routing, 272K input"
          max_tokens: 128000
          timeout: 3m0s
          retry_count: 3
          retry_delay: 1s
        gpt-5-mini:
          description: "GPT-5 Mini: Fast variant, half the cost"
          max_tokens: 128000
          timeout: 2m0s
          retry_count: 3
          retry_delay: 1s
        gpt-4o:
          description: "GPT-4o: Previous generation multimodal"
          max_tokens: 16384
          timeout: 1m0s
          retry_count: 3
          retry_delay: 1s

# Voice input/output configuration
voice:
  input_enabled: false             # Enable voice input/STT (requires OPENAI_API_KEY and sox)
  output_enabled: true             # Enable voice output/TTS (requires OPENAI_API_KEY and sox/afplay)
  headless: false                  # Headless mode (voice + auto-confirm)

# Execution behavior
execution:
  auto_confirm: false              # Auto-confirm all operations
  max_iterations: 10               # Maximum AI iterations per request

# Docker sandbox configuration
sandbox:
  enabled: false                   # Use Docker sandbox for command execution
  image: golang:1.24-alpine        # Docker image for sandbox

# Cellorg integration
cellorg:
  enabled: false                   # Enable cellorg advanced features (cells, RAG, etc.)
  config_path: config              # Path to cellorg configuration directory

# Output capture
output:
  capture_enabled: true            # Capture command output to show AI
  max_size_kb: 10                  # Maximum output size in KB to show AI

# Self-modification
self_modify:
  allowed: false                   # Allow AI to modify framework code

# Usage:
#
# 1. First run: alfa creates this file with defaults
# 2. Edit values as needed
# 3. CLI args override these settings:
#    --workbench, --project, --provider, --voice, --headless,
#    --auto-confirm, --max-iterations, --sandbox, --sandbox-image,
#    --enable-cellorg, --cellorg-config, --capture-output,
#    --max-output, --allow-self-modify
# 4. Changes are saved back to this file
#
# Examples:
#   alfa                                    # Uses alfa.yaml settings
#   alfa --provider openai                  # Override provider
#   alfa --voice --auto-confirm             # Enable voice + auto-confirm
#   alfa --project my-app --enable-cellorg  # Set project + enable cellorg
