# Cells define specific agent instances and their configuration

cell:
  id: "pipeline:file-transform"
  description: "File processing pipeline with ingestion, transformation, and output"
  debug: true

  # Pipeline orchestration settings
  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "15s"
    max_retries: 3
    retry_delay: "5s"
    health_check_interval: "10s"

  # Agent instances (specific IDs, not types)
  agents:
    - id: "file-ingester-demo-001" # ← Instance ID
      agent_type: "file-ingester" # ← Expected agent type
      ingress: "file:examples/pipeline-demo/input/*.txt"
      egress: "pub:new-file"
      dependencies: [] # ← No dependencies (starts first)
      config:
        digest: true
        digest_strategy: "delete"
        watch_interval_seconds: 2

    - id: "text-transformer-demo-001" # ← Instance ID
      agent_type: "text-transformer" # ← Expected agent type
      ingress: "sub:new-file"
      egress: "pipe:transform-data"
      dependencies: ["file-ingester-demo-001"] # ← Waits for file ingester
      config:
        transformation: "uppercase"
        add_metadata: true

    - id: "data-adapter-demo-001" # ← Instance ID
      agent_type: "adapter" # ← Expected agent type
      ingress: "sub:transform-requests"
      egress: "pub:transform-responses"
      dependencies: [] # ← Independent service
      config:
        supported_formats: ["json", "csv", "text"]
        max_request_size: "1MB"

    - id: "file-writer-demo-001" # ← Instance ID
      agent_type: "file-writer" # ← Expected agent type
      ingress: "pipe:transform-data"
      egress: "file:examples/pipeline-demo/output/processed_{{.timestamp}}.txt"
      dependencies: ["text-transformer-demo-001"] # ← Waits for transformer
      config:
        output_format: "txt"
        create_directories: true
# ---
# cell:
#   id: "controller:demo-controller"
#   description: "tbd"
#   debug: true
# ---
# cell:
#   id: "pubsub:pubsub-demo"
#   description: "tbd"

---
# Text Extraction Pipeline
cell:
  id: "pipeline:text-extraction"
  description: "Document text extraction pipeline with multi-format support and OCR"
  debug: true

  orchestration:
    startup_timeout: "45s"
    shutdown_timeout: "20s"
    max_retries: 3
    retry_delay: "5s"
    health_check_interval: "15s"

  agents:
    - id: "file-ingester-text-001"
      agent_type: "file-ingester"
      ingress: "file:examples/text-extraction/input/*.{pdf,docx,xlsx,txt,png,jpg}"
      egress: "pub:document-files"
      dependencies: []
      config:
        digest: false
        watch_interval_seconds: 3
        supported_extensions: [".pdf", ".docx", ".xlsx", ".txt", ".png", ".jpg", ".jpeg"]

    - id: "text-extractor-001"
      agent_type: "text-extractor"
      ingress: "sub:document-files"
      egress: "pub:extracted-text"
      dependencies: ["file-ingester-text-001"]
      config:
        enable_ocr: true
        ocr_languages: ["eng", "deu", "fra"]
        quality_threshold: 0.7
        timeout: "60s"
        output_format: "json"

    - id: "file-writer-text-001"
      agent_type: "file-writer"
      ingress: "sub:extracted-text"
      egress: "file:examples/text-extraction/output/extracted_{{.filename}}_{{.timestamp}}.json"
      dependencies: ["text-extractor-001"]
      config:
        output_format: "json"
        create_directories: true
        preserve_metadata: true

---
# Document Processing Pipeline with Intelligent Chunking
cell:
  id: "pipeline:document-processing"
  description: "Intelligent document processing with strategy-based chunking"
  debug: true

  orchestration:
    startup_timeout: "45s"
    shutdown_timeout: "20s"
    max_retries: 3
    retry_delay: "5s"
    health_check_interval: "15s"

  agents:
    - id: "file-ingester-docs-001"
      agent_type: "file-ingester"
      ingress: "file:examples/document-processing/input/*.{pdf,docx,txt}"
      egress: "pub:raw-documents"
      dependencies: []
      config:
        digest: false
        watch_interval_seconds: 3

    - id: "document-processor-001"
      agent_type: "document-processor"
      ingress: "sub:raw-documents"
      egress: "pub:processed-chunks"
      dependencies: ["file-ingester-docs-001"]
      config:
        strategy: "document_aware"
        chunk_size: 2048
        overlap_size: 256
        enable_ocr: true
        preserve_structure: true
        batch_processing: true
        workers: 4

    - id: "file-writer-chunks-001"
      agent_type: "file-writer"
      ingress: "sub:processed-chunks"
      egress: "file:examples/document-processing/output/{{.document_id}}/chunk_{{.chunk_index}}.txt"
      dependencies: ["document-processor-001"]
      config:
        output_format: "txt"
        create_directories: true
        include_metadata: true

---
# Advanced File Chunking Pipeline
cell:
  id: "pipeline:file-chunking"
  description: "Complete file chunking pipeline with splitting, processing, and synthesis"
  debug: true

  orchestration:
    startup_timeout: "60s"
    shutdown_timeout: "30s"
    max_retries: 3
    retry_delay: "10s"
    health_check_interval: "20s"

  agents:
    - id: "file-ingester-chunking-001"
      agent_type: "file-ingester"
      ingress: "file:examples/chunking-pipeline/input/*.*"
      egress: "pub:source-files"
      dependencies: []
      config:
        digest: false
        watch_interval_seconds: 5

    - id: "file-splitter-001"
      agent_type: "file-splitter"
      ingress: "sub:source-files"
      egress: "pub:file-chunks"
      dependencies: ["file-ingester-chunking-001"]
      config:
        default_chunk_size: 10485760  # 10MB
        split_strategy: "semantic"
        overlap_size: 512
        temp_dir: "/tmp/gox-chunks"

    - id: "chunk-processor-001"
      agent_type: "chunk-processor"
      ingress: "sub:file-chunks"
      egress: "pub:processed-chunks"
      dependencies: ["file-splitter-001"]
      config:
        processor_type: "text_processor"
        enable_keywords: true
        enable_sentiment: true
        worker_pool_size: 4
        job_timeout: "5m"

    - id: "chunk-synthesizer-001"
      agent_type: "chunk-synthesizer"
      ingress: "sub:processed-chunks"
      egress: "pub:synthesis-results"
      dependencies: ["chunk-processor-001"]
      config:
        synthesis_type: "document_summary"
        max_keywords: 50
        include_charts: true
        output_format: "json"

    - id: "file-writer-synthesis-001"
      agent_type: "file-writer"
      ingress: "sub:synthesis-results"
      egress: "file:examples/chunking-pipeline/output/synthesis_{{.document_hash}}_{{.timestamp}}.json"
      dependencies: ["chunk-synthesizer-001"]
      config:
        output_format: "json"
        create_directories: true
        preserve_metadata: true

---
# Academic Document Analysis Pipeline
cell:
  id: "pipeline:academic-analysis"
  description: "Specialized pipeline for academic document analysis and research paper processing"
  debug: true

  orchestration:
    startup_timeout: "60s"
    shutdown_timeout: "25s"
    max_retries: 2
    retry_delay: "10s"
    health_check_interval: "30s"

  agents:
    - id: "file-ingester-academic-001"
      agent_type: "file-ingester"
      ingress: "file:examples/academic-pipeline/papers/*.pdf"
      egress: "pub:research-papers"
      dependencies: []
      config:
        digest: false
        watch_interval_seconds: 10

    - id: "text-extractor-academic-001"
      agent_type: "text-extractor"
      ingress: "sub:research-papers"
      egress: "pub:paper-text"
      dependencies: ["file-ingester-academic-001"]
      config:
        enable_ocr: true
        ocr_languages: ["eng"]
        quality_threshold: 0.85
        timeout: "120s"

    - id: "document-processor-academic-001"
      agent_type: "document-processor"
      ingress: "sub:paper-text"
      egress: "pub:paper-sections"
      dependencies: ["text-extractor-academic-001"]
      config:
        strategy: "academic_paper"
        chunk_size: 1024
        overlap_size: 128
        preserve_structure: true
        include_metadata: true

    - id: "chunk-processor-academic-001"
      agent_type: "chunk-processor"
      ingress: "sub:paper-sections"
      egress: "pub:analyzed-sections"
      dependencies: ["document-processor-academic-001"]
      config:
        processor_type: "text_processor"
        enable_keywords: true
        enable_nlp: false
        max_lines: 5000

    - id: "chunk-synthesizer-academic-001"
      agent_type: "chunk-synthesizer"
      ingress: "sub:analyzed-sections"
      egress: "pub:paper-summary"
      dependencies: ["chunk-processor-academic-001"]
      config:
        synthesis_type: "document_summary"
        max_keywords: 25
        summary_length: 500
        include_sections: true

    - id: "file-writer-academic-001"
      agent_type: "file-writer"
      ingress: "sub:paper-summary"
      egress: "file:examples/academic-pipeline/summaries/{{.paper_title}}_analysis_{{.timestamp}}.json"
      dependencies: ["chunk-synthesizer-academic-001"]
      config:
        output_format: "json"
        create_directories: true
        preserve_metadata: true

---
# Intelligent Document Processing Pipeline (Framework-compliant)
cell:
  id: "pipeline:intelligent-document-processing"
  description: "Complete intelligent document processing with strategy selection and context enrichment"
  debug: true

  orchestration:
    startup_timeout: "90s"
    shutdown_timeout: "30s"
    max_retries: 3
    retry_delay: "10s"
    health_check_interval: "30s"

  agents:
    # Text extraction step
    - id: "text-extractor-idp-001"
      agent_type: "text-extractor"
      ingress: "sub:document-files"
      egress: "pub:extracted-text"
      dependencies: []
      config:
        enable_ocr: true
        ocr_languages: "eng,deu,fra"
        timeout_seconds: 120
        worker_pool_size: 4

    # Strategy selection step
    - id: "strategy-selector-idp-001"
      agent_type: "strategy-selector"
      ingress: "sub:extracted-text"
      egress: "pub:selected-strategies"
      dependencies: ["text-extractor-idp-001"]
      config:
        default_strategy: "document_aware"
        enable_content_analysis: true

    # Text chunking step
    - id: "text-chunker-idp-001"
      agent_type: "text-chunker"
      ingress: "sub:selected-strategies"
      egress: "pub:chunked-text"
      dependencies: ["strategy-selector-idp-001"]
      config:
        default_chunk_size: 2048
        max_chunk_size: 8192
        default_overlap: 256

    # Context enrichment step
    - id: "context-enricher-idp-001"
      agent_type: "context-enricher"
      ingress: "sub:chunked-text"
      egress: "pub:enriched-chunks"
      dependencies: ["text-chunker-idp-001"]
      config:
        enable_positional_context: true
        enable_semantic_context: true
        enable_structural_context: true
        enable_relational_context: true
        context_depth: 3

    # Output writing step
    - id: "chunk-writer-idp-001"
      agent_type: "chunk-writer"
      ingress: "sub:enriched-chunks"
      egress: "file:output/intelligent-processing/{{.request_id}}/{{.format}}/chunk_{{.index}}.{{.ext}}"
      dependencies: ["context-enricher-idp-001"]
      config:
        default_output_format: "json"
        output_directory: "output/intelligent-processing"
        create_directories: true
        preserve_metadata: true
        naming_scheme: "chunk_XXXX"

---
# Fast Document Processing Pipeline (simplified for speed)
cell:
  id: "pipeline:fast-document-processing"
  description: "Simplified document processing pipeline optimized for speed"
  debug: true

  orchestration:
    startup_timeout: "45s"
    shutdown_timeout: "20s"
    max_retries: 2
    retry_delay: "5s"
    health_check_interval: "15s"

  agents:
    # Text extraction
    - id: "text-extractor-fast-001"
      agent_type: "text-extractor"
      ingress: "sub:fast-document-files"
      egress: "pub:fast-extracted-text"
      dependencies: []
      config:
        enable_ocr: false  # Disable OCR for speed
        timeout_seconds: 30
        worker_pool_size: 2

    # Direct chunking without strategy selection
    - id: "text-chunker-fast-001"
      agent_type: "text-chunker"
      ingress: "sub:fast-extracted-text"
      egress: "pub:fast-chunked-text"
      dependencies: ["text-extractor-fast-001"]
      config:
        default_chunk_size: 1024
        max_chunk_size: 4096
        default_overlap: 128

    # Basic output without enrichment
    - id: "chunk-writer-fast-001"
      agent_type: "chunk-writer"
      ingress: "sub:fast-chunked-text"
      egress: "file:output/fast-processing/{{.request_id}}/chunk_{{.index}}.txt"
      dependencies: ["text-chunker-fast-001"]
      config:
        default_output_format: "text"
        output_directory: "output/fast-processing"
        create_directories: true
        preserve_metadata: false

---
# Research Paper Processing Pipeline (academic-focused)
cell:
  id: "pipeline:research-paper-processing"
  description: "Specialized pipeline for academic research paper processing"
  debug: true

  orchestration:
    startup_timeout: "120s"
    shutdown_timeout: "40s"
    max_retries: 3
    retry_delay: "15s"
    health_check_interval: "45s"

  agents:
    # Text extraction with high quality settings
    - id: "text-extractor-research-001"
      agent_type: "text-extractor"
      ingress: "sub:research-papers"
      egress: "pub:research-text"
      dependencies: []
      config:
        enable_ocr: true
        ocr_languages: "eng"
        timeout_seconds: 180
        worker_pool_size: 6

    # Academic strategy selection
    - id: "strategy-selector-research-001"
      agent_type: "strategy-selector"
      ingress: "sub:research-text"
      egress: "pub:research-strategies"
      dependencies: ["text-extractor-research-001"]
      config:
        default_strategy: "academic_paper"
        enable_content_analysis: true

    # Section-aware chunking
    - id: "text-chunker-research-001"
      agent_type: "text-chunker"
      ingress: "sub:research-strategies"
      egress: "pub:research-chunks"
      dependencies: ["strategy-selector-research-001"]
      config:
        default_chunk_size: 1024
        max_chunk_size: 3072
        default_overlap: 512  # Larger overlap for academic content

    # Deep context enrichment
    - id: "context-enricher-research-001"
      agent_type: "context-enricher"
      ingress: "sub:research-chunks"
      egress: "pub:research-enriched"
      dependencies: ["text-chunker-research-001"]
      config:
        enable_positional_context: true
        enable_semantic_context: true
        enable_structural_context: true
        enable_relational_context: true
        context_depth: 5  # Deeper analysis for academic content

    # Multiple format output
    - id: "chunk-writer-research-001"
      agent_type: "chunk-writer"
      ingress: "sub:research-enriched"
      egress: "file:output/research-papers/{{.request_id}}/{{.content_type}}/chunk_{{.index}}.json"
      dependencies: ["context-enricher-research-001"]
      config:
        default_output_format: "json"
        output_directory: "output/research-papers"
        create_directories: true
        preserve_metadata: true
        naming_scheme: "custom"

---
# Text Extraction Cells (native vs. HTTP OCR modes)

# Native text extraction with embedded Tesseract
cell:
  id: "extraction:native-text"
  description: "Text extraction using native Tesseract OCR (no external dependencies)"
  debug: true

  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "15s"
    max_retries: 2
    retry_delay: "10s"
    health_check_interval: "30s"

  agents:
    - id: "text-extractor-native-001"
      agent_type: "text-extractor-native"
      ingress: "sub:native-text-extraction"
      egress: "pub:extracted-text-native"
      dependencies: []
      config:
        enable_ocr: true
        timeout: 60000000000
        worker_pool_size: 4
        ocr_languages: "eng,deu,fra"
        enable_preprocessing: true
        enable_deskew: true
        enable_noise_removal: true
        contrast_enhancement: true

---
# HTTP OCR text extraction with containerized service
cell:
  id: "extraction:http-ocr"
  description: "Text extraction using containerized HTTP OCR service with await pattern"
  debug: true

  orchestration:
    startup_timeout: "60s" # Longer timeout for service dependency
    shutdown_timeout: "20s"
    max_retries: 3
    retry_delay: "15s"
    health_check_interval: "45s"

  agents:
    - id: "ocr-http-stub-001"
      agent_type: "ocr-http-stub"
      ingress: "sub:http-ocr-extraction"
      egress: "pub:extracted-text-http"
      dependencies: []
      config:
        service_url: "http://localhost:8080/ocr"
        request_timeout: 300000000000  # 5 minutes
        max_retries: 3
        retry_delay: 5000000000
        health_check_url: "http://localhost:8080/health"
        supported_formats: ".png,.jpg,.jpeg,.tiff,.bmp,.pdf"

---
# Production HTTP OCR with load-balanced service
cell:
  id: "extraction:http-ocr-production"
  description: "Production text extraction using load-balanced containerized OCR service"
  debug: false

  orchestration:
    startup_timeout: "90s"
    shutdown_timeout: "30s"
    max_retries: 5
    retry_delay: "20s"
    health_check_interval: "60s"

  agents:
    - id: "ocr-http-stub-prod-001"
      agent_type: "ocr-http-stub"
      ingress: "sub:production-ocr-extraction"
      egress: "pub:extracted-text-production"
      dependencies: []
      config:
        service_url: "http://localhost:8000/ocr" # Load-balanced service
        request_timeout: 600000000000  # 10 minutes for large documents
        max_retries: 5
        retry_delay: 10000000000       # 10 seconds
        health_check_url: "http://localhost:8000/health"
        supported_formats: ".png,.jpg,.jpeg,.tiff,.bmp,.pdf"

---
# Processing Cells for Content Analysis (replaces chunk_processor functionality)

# Multi-format content analysis cell
cell:
  id: "processing:content-analysis"
  description: "Comprehensive content analysis for text, JSON, XML, binary, and image data"
  debug: true

  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "15s"
    max_retries: 2
    retry_delay: "10s"
    health_check_interval: "30s"

  agents:
    # Text content analysis
    - id: "text-analyzer-001"
      agent_type: "text-analyzer"
      ingress: "sub:content-analysis-text"
      egress: "pub:analyzed-text"
      dependencies: []
      config:
        enable_nlp: false
        enable_sentiment: true
        enable_keywords: true
        max_lines: 10000
        max_keywords: 20

    # JSON content analysis
    - id: "json-analyzer-001"
      agent_type: "json-analyzer"
      ingress: "sub:content-analysis-json"
      egress: "pub:analyzed-json"
      dependencies: []
      config:
        enable_validation: true
        enable_schema_gen: true
        enable_key_analysis: true
        max_depth: 20
        max_keys: 1000
        enable_minification: false

    # XML content analysis
    - id: "xml-analyzer-001"
      agent_type: "xml-analyzer"
      ingress: "sub:content-analysis-xml"
      egress: "pub:analyzed-xml"
      dependencies: []
      config:
        enable_validation: true
        enable_schema_gen: true
        enable_namespace_analysis: true
        max_depth: 20
        max_elements: 1000
        enable_minification: false

    # Binary content analysis
    - id: "binary-analyzer-001"
      agent_type: "binary-analyzer"
      ingress: "sub:content-analysis-binary"
      egress: "pub:analyzed-binary"
      dependencies: []
      config:
        enable_hashing: true
        enable_entropy: true
        enable_magic_bytes: true
        max_analysis_size: 10485760
        enable_structural: true
        enable_compression: false

    # Image content analysis
    - id: "image-analyzer-001"
      agent_type: "image-analyzer"
      ingress: "sub:content-analysis-image"
      egress: "pub:analyzed-image"
      dependencies: []
      config:
        enable_metadata: true
        enable_dimensions: true
        enable_color_analysis: true
        max_analysis_size: 10485760
        enable_thumbnail: false
        enable_quality: true

---
# Fast content analysis cell (optimized for speed)
cell:
  id: "processing:fast-analysis"
  description: "Fast content analysis with reduced features for high-throughput scenarios"
  debug: false

  orchestration:
    startup_timeout: "15s"
    shutdown_timeout: "10s"
    max_retries: 1
    retry_delay: "5s"
    health_check_interval: "20s"

  agents:
    # Fast text analysis
    - id: "text-analyzer-fast-001"
      agent_type: "text-analyzer"
      ingress: "sub:fast-analysis-text"
      egress: "pub:fast-analyzed-text"
      dependencies: []
      config:
        enable_nlp: false
        enable_sentiment: false
        enable_keywords: true
        max_lines: 1000
        max_keywords: 10

    # Fast JSON analysis
    - id: "json-analyzer-fast-001"
      agent_type: "json-analyzer"
      ingress: "sub:fast-analysis-json"
      egress: "pub:fast-analyzed-json"
      dependencies: []
      config:
        enable_validation: true
        enable_schema_gen: false
        enable_key_analysis: false
        max_depth: 10
        max_keys: 100
        enable_minification: true

    # Fast binary analysis
    - id: "binary-analyzer-fast-001"
      agent_type: "binary-analyzer"
      ingress: "sub:fast-analysis-binary"
      egress: "pub:fast-analyzed-binary"
      dependencies: []
      config:
        enable_hashing: true
        enable_entropy: false
        enable_magic_bytes: true
        max_analysis_size: 1048576  # 1MB
        enable_structural: false
        enable_compression: false

---
# Specialized text analysis cell
cell:
  id: "processing:text-analysis-deep"
  description: "Deep text analysis with NLP and advanced features"
  debug: true

  orchestration:
    startup_timeout: "45s"
    shutdown_timeout: "20s"
    max_retries: 3
    retry_delay: "15s"
    health_check_interval: "40s"

  agents:
    # Deep text analysis with all features
    - id: "text-analyzer-deep-001"
      agent_type: "text-analyzer"
      ingress: "sub:deep-text-analysis"
      egress: "pub:deep-analyzed-text"
      dependencies: []
      config:
        enable_nlp: true
        enable_sentiment: true
        enable_keywords: true
        max_lines: 50000
        max_keywords: 50

---
# Specialized JSON/XML analysis cell
cell:
  id: "processing:structured-data-analysis"
  description: "Specialized analysis for structured data formats (JSON, XML)"
  debug: true

  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "15s"
    max_retries: 2
    retry_delay: "10s"
    health_check_interval: "30s"

  agents:
    # Comprehensive JSON analysis
    - id: "json-analyzer-comprehensive-001"
      agent_type: "json-analyzer"
      ingress: "sub:structured-data-json"
      egress: "pub:comprehensive-analyzed-json"
      dependencies: []
      config:
        enable_validation: true
        enable_schema_gen: true
        enable_key_analysis: true
        max_depth: 50
        max_keys: 10000
        enable_minification: false

    # Comprehensive XML analysis
    - id: "xml-analyzer-comprehensive-001"
      agent_type: "xml-analyzer"
      ingress: "sub:structured-data-xml"
      egress: "pub:comprehensive-analyzed-xml"
      dependencies: []
      config:
        enable_validation: true
        enable_schema_gen: true
        enable_namespace_analysis: true
        max_depth: 50
        max_elements: 10000
        enable_minification: false

---
# Specialized binary/image analysis cell
cell:
  id: "processing:binary-media-analysis"
  description: "Specialized analysis for binary data and media files"
  debug: true

  orchestration:
    startup_timeout: "60s"
    shutdown_timeout: "30s"
    max_retries: 2
    retry_delay: "20s"
    health_check_interval: "45s"

  agents:
    # Comprehensive binary analysis
    - id: "binary-analyzer-comprehensive-001"
      agent_type: "binary-analyzer"
      ingress: "sub:binary-media-binary"
      egress: "pub:comprehensive-analyzed-binary"
      dependencies: []
      config:
        enable_hashing: true
        enable_entropy: true
        enable_magic_bytes: true
        max_analysis_size: 52428800  # 50MB
        enable_structural: true
        enable_compression: true

    # Comprehensive image analysis
    - id: "image-analyzer-comprehensive-001"
      agent_type: "image-analyzer"
      ingress: "sub:binary-media-image"
      egress: "pub:comprehensive-analyzed-image"
      dependencies: []
      config:
        enable_metadata: true
        enable_dimensions: true
        enable_color_analysis: true
        max_analysis_size: 52428800  # 50MB
        enable_thumbnail: true
        enable_quality: true

---
# Storage Service Cell
cell:
  id: "service:storage"
  description: "Storage service providing KV, graph, files, and full-text capabilities"
  debug: true

  orchestration:
    startup_timeout: "60s"
    shutdown_timeout: "30s"
    max_retries: 3
    health_check_interval: "30s"

  agents:
    - id: "storage-service-001"
      agent_type: "godast-storage"
      dependencies: []
      # Service mode - no traditional ingress/egress
      config:
        # Storage configuration
        data_path: "/tmp/gox-storage-service"
        max_file_size: 104857600  # 100MB
        enable_kv: true
        enable_graph: true
        enable_files: true
        enable_fulltext: true

        # Service mode configuration
        storage_mode: "service"
        listen_port: 9002
        enable_cors: true
        log_requests: true
        auth_required: false
        max_concurrent_requests: 100
        request_timeout: "30s"

  # Environment variables for service mode
  environment:
    GOX_LOG_LEVEL: "info"
    GOX_STORAGE_MODE: "service"
    GOX_SERVICE_PORT: "9002"
    GOX_METRICS_ENABLED: "true"

---
# Document Summary Synthesis Cell
cell:
  id: "synthesis:document-summary"
  description: "Document summarization pipeline using Framework-compliant agents"
  debug: true

  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "15s"
    max_retries: 2
    health_check_interval: "15s"
    execution_order: ["summary-agent"]

  agents:
    - id: "summary-agent"
      agent_type: "summary-generator"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["synthesis_result"]
      config:
        max_keywords: 25
        max_topics: 12
        summary_length: 750
        output_format: "json"
        enable_sections: true

  environment:
    GOX_LOG_LEVEL: "info"

---
# Full Synthesis Analysis Cell
cell:
  id: "synthesis:full-analysis"
  description: "Comprehensive synthesis pipeline with all available analyzers"
  debug: true

  orchestration:
    startup_timeout: "45s"
    shutdown_timeout: "30s"
    max_retries: 3
    health_check_interval: "20s"
    execution_order: ["summary-agent", "indexer-agent", "metadata-agent", "report-agent", "dataset-agent"]

  agents:
    - id: "summary-agent"
      agent_type: "summary-generator"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["summary_complete"]
      config:
        max_keywords: 30
        max_topics: 15
        summary_length: 1000
        enable_sections: true

    - id: "indexer-agent"
      agent_type: "search-indexer"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["index_complete"]
      config:
        max_terms: 15000
        min_term_frequency: 2
        calculate_positions: true
        score_threshold: 0.05

    - id: "metadata-agent"
      agent_type: "metadata-collector"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["metadata_complete"]
      config:
        include_chunk_metadata: true
        include_file_metadata: true
        generate_schema: true
        max_metadata_size: 20971520  # 20MB

    - id: "report-agent"
      agent_type: "report-generator"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["report_complete"]
      config:
        include_charts: true
        include_tables: true
        include_recommendations: true
        max_recommendations: 8

    - id: "dataset-agent"
      agent_type: "dataset-builder"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["dataset_complete"]
      config:
        include_metadata: true
        generate_schema: true
        enable_validation: true
        max_records: 250000

  environment:
    GOX_LOG_LEVEL: "info"
    GOX_PARALLEL_PROCESSING: "true"

---
# Search-Ready Synthesis Cell
cell:
  id: "synthesis:search-ready"
  description: "Optimized pipeline for search and discovery use cases"
  debug: true

  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "20s"
    max_retries: 2
    health_check_interval: "15s"
    execution_order: ["summary-agent", "indexer-agent"]

  agents:
    - id: "summary-agent"
      agent_type: "summary-generator"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["summary_for_search"]
      config:
        max_keywords: 40
        max_topics: 20
        summary_length: 500
        enable_sections: false  # Simplified for search

    - id: "indexer-agent"
      agent_type: "search-indexer"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["search_index_ready"]
      config:
        max_terms: 20000
        min_term_frequency: 1
        calculate_positions: true
        index_format: "json"
        score_threshold: 0.01  # Lower threshold for comprehensive indexing

  environment:
    GOX_LOG_LEVEL: "info"
    GOX_SEARCH_OPTIMIZATION: "true"

---
# Data Export Synthesis Cell
cell:
  id: "synthesis:data-export"
  description: "Structured data export pipeline for analytics and integration"
  debug: true

  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "20s"
    max_retries: 2
    health_check_interval: "15s"
    execution_order: ["metadata-agent", "dataset-agent"]

  agents:
    - id: "metadata-agent"
      agent_type: "metadata-collector"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["metadata_collected"]
      config:
        include_chunk_metadata: true
        include_file_metadata: true
        generate_schema: true
        output_format: "json"

    - id: "dataset-agent"
      agent_type: "dataset-builder"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["dataset_exported"]
      config:
        output_format: "json"
        include_metadata: true
        generate_schema: true
        enable_validation: true
        naming_scheme: "export_XXXX"
        max_records: 500000  # Larger for data export

  environment:
    GOX_LOG_LEVEL: "info"
    GOX_EXPORT_MODE: "structured"

---
# Report Generation Cell
cell:
  id: "synthesis:reporting"
  description: "Comprehensive reporting pipeline for business intelligence"
  debug: true

  orchestration:
    startup_timeout: "30s"
    shutdown_timeout: "20s"
    max_retries: 2
    health_check_interval: "15s"
    execution_order: ["metadata-agent", "report-agent"]

  agents:
    - id: "metadata-agent"
      agent_type: "metadata-collector"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["metadata_for_reporting"]
      config:
        include_chunk_metadata: true
        include_file_metadata: true
        generate_schema: false  # Skip schema for reporting

    - id: "report-agent"
      agent_type: "report-generator"
      dependencies: []
      ingress:
        channels: ["synthesis_request"]
      egress:
        channels: ["report_generated"]
      config:
        include_charts: true
        include_tables: true
        include_recommendations: true
        report_format: "json"
        max_recommendations: 10

  environment:
    GOX_LOG_LEVEL: "info"
    GOX_REPORTING_MODE: "comprehensive"

---
# RAG Knowledge Backend Pipeline for Alfa Integration
cell:
  id: "rag:knowledge-backend"
  description: "RAG pipeline providing semantic code search and context retrieval for Alfa AI assistant"
  debug: true

  orchestration:
    startup_timeout: "60s"
    shutdown_timeout: "30s"
    max_retries: 3
    retry_delay: "5s"
    health_check_interval: "15s"

  agents:
    # RAG Orchestrator - Coordinates embedding, search, and context assembly
    # Alfa subscribes to rag-queries topic and publishes results
    - id: "rag-agent-001"
      agent_type: "rag-agent"
      dependencies: ["embedding-agent-001", "vectorstore-agent-001", "godast-storage-001"]
      ingress: "sub:{project_id}:rag-queries"
      egress: "pub:{project_id}:rag-results"
      config:
        top_k: 5
        rerank: true
        max_context_tokens: 4000
        include_surrounding_lines: 3
        score_threshold: 0.5

    # Embedding Generator - Converts text to vectors using OpenAI
    - id: "embedding-agent-001"
      agent_type: "embedding-agent"
      dependencies: []
      ingress: "sub:embedding-requests"
      egress: "pub:embeddings"
      config:
        provider: "openai"
        model: "text-embedding-3-small"
        batch_size: 100
        cache_enabled: true
        timeout: 30000000000  # 30s
        dimensions: 1536

    # Vector Store - Similarity search for code chunks
    - id: "vectorstore-agent-001"
      agent_type: "vectorstore-agent"
      dependencies: []
      ingress: "sub:vector-operations"
      egress: "pub:vector-results"
      config:
        index_type: "flat"
        dimensions: 1536
        max_elements: 1000000

    # Godast Storage - Content storage and retrieval
    - id: "godast-storage-001"
      agent_type: "godast-storage"
      dependencies: []
      ingress: "sub:storage-operations"
      egress: "pub:storage-results"
      config:
        storage_path: "/var/lib/gox/projects/default/storage"
        enable_kv: true
        enable_graph: true
        enable_file: true
        enable_search: true

  environment:
    OPENAI_API_KEY: "${OPENAI_API_KEY}"
    GOX_DATA_ROOT: "/var/lib/gox"
    GOX_PROJECT_ID: "default"
    GOX_LOG_LEVEL: "debug"
    GOX_DEBUG: "true"
